<!DOCTYPE html>
<html lang="en">
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1" charset="utf-8">
				<title>Trying To Peek Past '403 Forbidden'</title>

						<style>
		@import url(https://fonts.googleapis.com/css?family=Rajdhani:300);
		html, body {
		  background-color: #212121;
		      width: 100%;
		  height: 100%;
			margin: 0 auto;
		  font-family: 'Rajdhani', sans-serif;
		  font-size: 16px;
		}
		img {
		    border-radius: 12px;
		    border: 2px solid #212121;
		   display: block;
		    margin-left: auto;
		    margin-right: auto;
		    max-width: 100%;
		    height: auto;
		    }
		    img:hover {
		    -webkit-transform: scaleX(-1);
		    transform: scaleX(-1);
		    }

			.header{
			text-align: center;
			color: #00bebe;
			font-size: 3.5em;
		}
		.blog{
			text-align: center;
			color: #00bebe;
			font-size: 1.5em;
		}
		code{
			text-align: center;
			color:white;
			font-size: 18px;
			white-space: pre-wrap;

		}
		a{
			color:  #6698b4;
		}
		span{
			color:white;
		}
		hr{
			color: #00bebe;
		}

</style>
	</head>
	<body>
	<div class="header">
			<h><u>Trying To Peek Past '403 Forbidden'</u></h>
		</div>

			<div class="blog">
				<br>
				<img src="https://i.imgur.com/d9xuQMT.jpg" alt="403 Forbidden" style="width:750px;height:250px";></img>
				<p>A <a href="https://en.wikipedia.org/wiki/HTTP_403">'403 Forbidden' error</a> means that we don't have permission to access
				the specified location. However, it may be possible for us to see was exists beyond.<br>
			Let's take a senario where we may come across this situation.<br>
		While doing some reconnaissance on a website, we noticed two interesting directory paths:</p>
		<code>
www.example.com/uploads
www.example.com/documents
		</code>
	<p>First we take a look at <span>www.example.com/documents</Span>. It turns out to contains file that we can publicly access.
		Next we check out <span>www.example.com/uploads</span>. At this location we are show '403 Forbidden' that prevents us form seeing any futher
			files.<br>
		By typing a <a href="https://www.exploit-db.com/google-hacking-database/">Google Dork</a> into the Google search engine, we may be able to find links to some files that were previously crawled.</p>
		<code>
site:example.com filetype:pdf OR filetype:docx OR filetype:xlsx OR filetype:pptx OR filetype:doc OR filetype:xls OR filetype:ppt
		</code>
		<p>Another option is to find a script that will do this for us. <a href="https://github.com/methos2016/recon-ng">Recon-ng</a> has a module for this.</p>
		<code>
recon-ng
show modules
use recon/domains-contacts/metacrawler
set SOURCE example.com
		</code>
	<img src="https://i.imgur.com/5iphWvm.png" alt="recon-ng" style="width:750px;height:250px";></img>
	<p>The results above show that we might have come across some sensitive files. Now we can directly access these files without
	being greeted by the '403 Forbidden' error.</p>
<hr>
</body>
</html>
